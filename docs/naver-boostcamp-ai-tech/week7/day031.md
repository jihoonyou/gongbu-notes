# day 31

## Image classification 1
### Why is visual perception important?
- 인공지능은 인지능력과 지각능력을 포함. 즉, visual perception또한 AI의 일부분이다
- 인공지능의 reference는 인간
- (아기의 경우) 오감을 활용하여 지각능력 및 사고능력의 발전
    - 지각능력은 입력과 출력에 관련
- 단순 오감을 넘어 social perception 등 다양한 감깍을 통해 정보를 얻음
    - 사람의 표정을 보고, 악수를 통해 느끼고, 발표자의 제스처를 통해
- machine perception은 아직 더 연구가 필요한 분야 (오감외에 다른 것도)
- 오감중 vision이 중요한 이유는 다른 오감에 비해 시각에 많이 의지하기 때문
    - 75%의 정보가 눈을 통해 들어오고
    - 뇌의 50%가 시각적 정보를 processing하는데 사용됨
### What is computer vision?
- 사람: 눈을 통해 망막에 객체가 맺히고, 뇌가 해석하여 정보를 인지
- machine: 카메라를 통해 물체를 인지하고, GPU & Alogrithm이 정보를 인지 및 구조화(자료구조 = Representation)
- Computer Graphics(rendering technique): Representation을 2-D image로, 분석한 정보로 장면 재구성
- Computer Vision(Inverse rendering): 물체를 구조화
    - 기계에게 사물을 인지시키는 것
    - Input은 visual data(image or video)
    - 다양한 visual perception
        - Color, Motion, 3D, Semantic-level, Social(emotion), visumotor percetion
    - 사람의 시각 능력을 기반으로 한 computer vision algorithm도 CV에 포함됨
- 눈과 시각을 담당하는 부분은 똑바로 된 사진에 대한 사람들의 사진을 많이봄. 즉, 뒤집어진 사진에 대해 사람의 시각 기능이 bias되어 학습되어 있다
    - 뒤집혀진 이상한 사진의 예시를 원래로 돌리기 전, 눈 과 입의 이상함을 감지 - x
    - 뒤집혀진 이상한 사진의 예시를 원래로 돌렸을 때, 눈 과 입의 이상함을 감지 - x
- machine learning은 전문가가 feature extraction과 classification을 implement
- deep learning은 gradient descent를 사용하여 feature extraction + classification implement

### What is classification
- classifier
    - 입력: 영상
    - 출력: 영상에 해당하는 클래스
- 모든 데이터를 저장할 수 있다면? K-NN으로 모든 문제를 검색문제화하여 해결할 수 있음
    - K Nearest Neighbors: query data를 기준으로 가까운 K개의 데이터들의 label을 통해 분류
    - 모든 데이터가 있다면 영상 분류문제는 검색 데이터가 됨
    - 하지만 영상간의 유사도 정의가 어렵고, time complexity 및 memory complexity가 infinite하다는 문제로 접목 불가
### Convolutional Neural Networks
- 방대한 데이터를 제한된 복잡도 시스템에 압축해서 (neural networks parameter에) 녹여 넣는 것
    - fully connected layer는 전체 그림, 모든 픽셀의 weight를 받으므로 평균 이미지 외에는 표현이 불가능
        - 즉, crop되거나 조금 다른 패턴의 같은 그림에 대해 잘못된 결론 도출
        - 전체 그림을 weight parameter마다.. 다 fully connected
    - locally connected nueral networks로 대체 
        - 전체가 아니라 filter를 통해 일부분의 특징을 뽑는다(local feature learning )
        - 부분별(지역적) 특징 도출 (ex- 말의 일부분 특징을 뽑는등)
- CNN은 다른 vision tasks들의 베이스로 사용이 된다

### AlexNet
- Receptive field: cnn feature가 도출된 input space
    - 특징의 한 부분이 도출되는 단계적 intput layer
        - 하나의 값을 위해 어느정도 영역까지 참조 되었는지
### VGGNet
- local response normalization 안씀 대신 Batch Normalization
- 3 by 3 conv filter(w/ stride 1), 2 by 2 max pooling만 사용
- 특징: deeper architecture, simpler architecture, better performance, better generalization
    - keeping receptive field sizes large enough (layer를 deep하게 가져가며 receptive field의 사이즈는 크게)
    - fewer parameters
    - Deeper with more non-linearities
    - 작은 커널 사이즈로 스택을 많이 쌓아서 큰 receptive size를 얻음 (이미지 영역에 더 많은 부분을 고려했다)
    - 3 fully-connected FC layers1

## Annotation data efficient learning
### Learning repsentation of dataset
> Learning repsentation from a dataset
> Neural networks learn compact features (information) of a dataset
- data를 컴퓨터가 이해할 수 있는 형태로 compress
> Dataset is (almost) always biased
- 사진 데이터들은 대부분 bais되어 있음
    - 여기서 bias는 대부분 패턴이 있다는 말
> Thr training dataset is sparse samples of real data
- 실제 데이터는 방대하고 빽빽하지만, sample traing dataset은 sparse하고 못본 데이터가 많다
- 데이터셋으로 트레이닝을 하더라도, 실제 이미지의 distribution을 다 채울 수 없는 문제가 발생
    - 밝은 사진만 dataset에 있을 경우, 어두운 사진은 인식 못할수도..
- Data Augmentation: data가 주어졌을 때 더 풍부하게 만드는 것
    - data를 좀 더 늘리는 것 (그래서 실제와 가깝게 더 많은 데이터 충족)
    - brightness adjustment, roate, flip, crop, affine transformation, cutmix
- RandAgument: 영상 처리기법을 조합
    - 성능 좋은 augmentation policy를 search 하는 것
    - Automaticaaly finding the best seqeunce of augmentations to apply
    1. Which augmentation to apply
    2. Magnitude of aguemenation to apply

### Transfer learning
- 현실적으로 양질적인 데이터셋을 모으기 쉽지 않음
- 적은 데이터셋을 훈련하기에 적합한 방법임
- Transfer learning: 기존에 학습된 것을 활용하여 새로운 task에 적용, 한 데이터셋에서 배운 지식을 다른 데이터셋에서 활용하는 것
    - Knowledge learned from one dataset can be applied to other datasets
    - 사진에서 공통적으로 잔디가 나왔다던가.. 바퀴 또는 동물의 특징을 추출
        - 서로 다른 dataset에서 pre-trained된 지식들이 사용될 수 있다는 것
- Approach 1: Transfer knowledge from a pre-trained task to a new task
    - 마지막, fully conneceted layers를 잘라내고, 새로운 FC layer만 학습 (Freeze weight)
- Approach 2: Fine-tuning the whole model
    - 앞단을 freeze말고 learning rate을 적게 잡고, FC Layer를 바꾸고 전체 학습
    - set learning rates differently
### Knowledge distilliation
> Passing what model learned to'another' smaller model (Techaer-student learning)
- 말 그대로 지식을 주입
- 작은 모델에 지식을 주입하는 것, 작은 모델(not-trained)은 큰 모델(already-trained)에서 데이터를 전달받음
- label을 맞추는 것이 아닌 비슷하게 행동하게 train하는 것이므로 unsupervised learning 이다.
    - KL div. loss - 둘의 차이를 구하고 backpropagation으로 student model만 학습
    - 두 개의 distribution이 비슷하게 학습
        - student model이 teacher model을 따라하게 하는 학습법
- data label이 있으면 distillation loss외에 true label(one-hot encoded label)을 통해 student loss도 구한다
    - student loss (Softmax (T=1))
    - distillation loss (Softmax (T=t))
- hard label(one hot vector) -> (dataset으로부터) 답이 맞는지 아닌지 (dataset에서 도출) 
- soft label -> 모델의 생각을 아는데 유용 (model에서 도출)
    - softmax(T=1) - 정답 유추 파악에 사용
        - 입력의 값을 극단적으로 벌려줌
    - softmax(T=t) - distillation에서 사용
        - 출력이 좀 더 smooth하게(큰 값 T(temperature)로 나누어서)
        - 0과 1의 극단적인 값만 갖는 것이 아닌 중간값도 갖게하여 student가 teacher를 더 잘 따라하게
- Semantic information is not considered in **distillation**
    - soft label의 각각 의미보다 전반적인 distribution을 따라하는 것이 더 중요
    - 그러므로, soft label과 student loss는 전혀 다른 task일 수 있음
        - 선생님 mimick vs. 정답과의 비교
- Distillation loss
    - KLdiv(soft label, Soft prediction)
    - teacher label과 student label의 추론결과의 차이
    - teacher network를 mimick하면서 배움
- Student loss
    - CrossEntropy(Hard label, Soft prediction)
    - student network의 출력과 정답 label의 차이
    - Learn the right answer
- knowledge distillation의 loss function은 weighted sum of distillation loss and student loss

### Semi-supervised learning
- 상대적으로 많은 un-labled data를 labeled datasets으로 pseudo label하여 사용하기 위함
    - labeled data로 model을 훈련시키고, 해당 모델로 unlabled data의 label 유추.
    - labeled dataset과 psudo-labeled dataset으로 다시 모델 학습

### self-training
- data augmentation
    - 기존의 데이터를 바꾸어 더 많은 데이터를 사용하는 것
- Knowledge distillation
    - 이미 학습된 teacher data의 지식을 student data에 주입시키는 것 
- Semi-supervised learning
    - unlabeled된 데이터에 pseudo label한 후 사용하는 것
### self-training
- Agumentation + Teacher-Student networks + semi-supervised learning
    - 이전과 다르게 student model이 조금씩 더 커짐
1. 기존 teacher model을 labeled data로 학습
2. 학습된 teacher model로 unlabeled data를 pseudo-label로 만듦
3. labeled data와 pseudo-label data를 randAugment하고 student model을 훈련시킴
4. student model을 teacher model로 선정(더 커진 student model)
5. 2~4번 반복

## 피어세션 및 정리
- 수업듣는 속도가 각자 달라서 많은 토론은 이루어지지 않았다. 음.. 조교님의 코드의 epoch의 명시와 다른 코드 스타일에 조금 헷갈리거나 다른 코드방식을 이해할 필요가 있다는 것을 느낌
da
