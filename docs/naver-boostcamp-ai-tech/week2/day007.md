# day 7 경사하강법

## 경사하강법(순한맛) 경사하강법(매운맛)
- 해당 섹션은 수업자료 PDF에 필기를 진행하였습니다.
### 미분이 뭔가요?
```
import sympy as sym
from sympy.abc import x

sym.diff(sym.poly(x**2 + 2*x + 3),x)
```
- 코드로 미분

### 경사하강법: 알고리즘
gradient: 미분을 계산하는 함수
init: 시작점
lr:학습률
eps: 알고리즘 종료조건

var = init
grad = gradient(var)
while(abs(grad) > eps): # 미분의 값이 eps보다 작아지만!, 컴퓨터로 미분을 계산할 때 정확히 0 이되는 것이 불가능하므로
   var = var - lr * grad
   grad = gradient(var) 
- 구현 실행 파일은 workspace week2에

### 변수가 벡터이면요?
```
import sympy as sym
from sympy.abc import x,y

sym.diff(sym.poly(x**2 + 2*x*y + 3) + sym.cos(x + 2*y),x)
```
- 벡터가 입력인 다변수 함수의 경우 편미분을 사용

gradient vector
- 각 변수 별로 편미분을 계산한 것

### 벡터 경사하강법:알고리즘
var = init
grad = gradient(var)
while(norm(grad) > eps): # 미분의 값이 eps보다 작아지만!, 컴퓨터로 미분을 계산할 때 정확히 0 이되는 것이 불가능하므로
   var = var - lr * grad
   grad = gradient(var) 
- abs 대신 norm
- 구현 실행 파일은 workspace week2에

### 선형 회귀분석 복습
- `np.linalg.pinv`
    - 역행렬을 계산할 수 없을 때, moore-Penrose 역행렬(유사 역행렬)

### 경사하강법으로 선형회귀 계수 구하기
- 강의영상 03:47 증명
    - Special thanks to Changeun

### 경사하강법 기반 선형회귀 알고리즘
Input: X, y, lr, T, Output: beta
    norm: L2-노름을 계산하는 함수
    lr: 학습률, T: 학습횟수

for t in range(T):
    error = y - X @ beta
    grad = - transpose(X) @ error # error = 공식에서의 (y - X
    giyoubeta)와 같음
    beta = beta - lr * grad
- gradient_vector 특정 값 이하로 떨어질 때까지 학습하는 알고리즈도 괜찮고, 위와 같이 학습횟수를 지정해서 할 수 있음
- 비선형회귀 문제의 경우 목적식이 볼록하지 않을 수 있으므로 수렴이 보장되지 않음
- 구현 실행 파일은 workspace week2에

### 확률적 경사하강법
- 모든 데이터를 사용해서 업데이트하는 대신 데이터 한개 또는 일부만을 화용하여 업데이트
    - 모든 데이터를 사용한 gradient descent와 유사하기는 하지만 같을 수는 없음
    - 하지만, sgd의 기대값이 유사할 것이다라는 것이 확률적으로 증명 (미니배칯 연산)
    - 연산적으로 효율

## 개인 공부

### P-stage 주제 정리 week 9~12 - 프로젝트 (1) 머신러닝 파이프라인 구축

#### 정형 데이터 분류(Tabular Classification)
정형데이터(Structured data): 데이터베이스의 정해진 규칙(Rule)에 맞게 데이터를 들어간 데이터 중에 수치 만으로 의미 파악이 쉬운 데이터
- 그 값이 의미를 파악하기 쉽고, 규칙적인 값으로 데이터가 들어갈 경우 정형 데이터
- Gender(male,female), Age(25,40)

비정형 데이터(Unstructured data): 정해진 규칙이 없어서 값의 의미를 쉽게 파악하기 힘든 데이터(정형 데이터와 반대되는 단어)
- 텍스트, 음성, 영상과 같은 데이터

반정형 데이터(Semi-structured data): 완전한 정형이 아니라 약한 정형 데이터
- HTML이나 XML과 같은 포맷

[참조1](https://needjarvis.tistory.com/502)

[참조2](https://m.blog.naver.com/gkenq/10182562869)

#### 이미지 분류(Image Classification)
이미지 분류: 물체 분류(Object classification)라고도 하며 이미지 전체 혹은 이미지 안의 물체(object)의 종류를 구분하는 작업
- 종류의 개수가 두개면 이진 분류, 여러 개면 다중 분류
    - 이진 분류: 강아지 vs 고양이
    - 다중 분류: 손으로 쓴 숫자(0~9)

물체 위치인식(Object Localization): 이미지 안의 물체가 이미지의 어느 영역에 있는지 위치 정보를 출력해 주는 것
- 주로 물체를 사각형(Bouding box)으로 표시를 하는데 사각형의 왼쪽 위(left top)와 오른쪽 아래(right bottom) 좌표를 출력

물체 검출(Object Detection): 분류(classification)하는 과정과 물체가 어디에 있는지 위치정보를 알려주는(Localization) 과정이 동시에 수행되는 것

Object Recognition: 대개의 경우 Object detection 과 같은 의미로 쓰인다. 그러나 detection 은 object 의 존재 유무만 의미하고 recognition 이 object 의 종류를 아는 것이라고 해석하여 object detection 이 object recognition 보다 더 작은 의미로 해석되는 경우도 종종 있다

Object segmentation: object detection 을 통해 검출된 object 의 형상을 따라서 object 의 영역을 표시하는 것
- 보통 이미지의 각 pixel 을 classification 해서 위와 같은 결과 값을 도출한다
- 단순히 전경 foreground 와 배경 background 를 구분하는 용도로 쓰이기도 한다

Image Segmentation: 이미지의 영역을 분할하는 것 
- 이런 분할된 영역들을 적당한 알고리즘을 사용해 합쳐서 object segmentation 을 수행

Semantic Segmentation: Semantic segmentation이란 Object segmentation 을 하되 같은 class 인 object 들은 같은 영역 혹은 색으로 분할하는 것

Instance Segmentation: Instance segmentation이란 semantic segmentation 에서 한발 더 나아가서, 같은 class 이더라도 서로 다른 instance 들을 구분해주는 것

이미지 캡셔닝(Image captioning): 이미지를 설명하는 문장을 만들어 내는 작업

[참조1](https://ardino-lab.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%A2%85%EB%A5%98-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EB%B6%84%EB%A5%98-%EB%AC%BC%EC%B2%B4-%EC%9C%84%EC%B9%98%EC%9D%B8%EC%8B%9D-%EB%AC%BC%EC%B2%B4-%EA%B2%80%EC%B6%9C/)

[참조2](https://light-tree.tistory.com/75)

#### 한국어 언어 모델 학습 및 다중 과제 튜닝(KLUE)
Korean Language Understanding Evaluation

[참조](https://www.facebook.com/101591091705826/posts/168611305003804/)

#### 데이터 탐색을 위한 시각화(Visualization for EDA) - Exploratory Data Analysis
Exploratory Data Analysis: 데이터를 수집했을때 이를 다양한 각도에서 관찰하고 이해하는 과정
- 데이터의 분포 및 값을 검토하여 수집한 데이터가 어떤 것을 나타내는지를 더 잘 이해하고, 수집한 데이터에 대한 잠재적인 문제를 발견하여 본격적인 분석에 들어가기 전에 수집의사를 결정하고 판단

[참조1](https://untitled-memo-2019.tistory.com/1)

### P-stage 주제 정리 week 13~20 - 프로젝트 (2) 모델 성능 개선과 AI 엔지니어링

#### 객체 영역 구분과 검출(Image Segmentation & Object Detection)
- 위의 Image Classification에서 간단히 설명

#### 한국어 기계 독해(Machine Reading Comprehension)
Machine Reading Comprehension: 기계가 글과 질문을 읽고 추론을 하여 글에서 정답을 찾아주는 것
모델들의 공통적인 구조
- Encoder
    - 질의와 문맥을 벡터로 표현
- Co-attention
    - 상호 Attention을 통해 문맥과 질의 간의 관계 파악
- Output
    - 질문에 해당하는 정답 언어의 시작과 끝 위치 출력

[참조](https://www.slideshare.net/NaverEngineering/ss-108892693)

[참조2](https://m.post.naver.com/viewer/postView.nhn?volumeNo=14231181&memberNo=3185448)

#### 한국어 Dialogue State Tracking(DST)
Dialogue State Tracking: 말 그대로 대화의 상황을 추적하는 작업
- 조금 모호한듯?
[참조](https://m.blog.naver.com/PostView.nhn?blogId=qbxlvnf11&logNo=221853531686&proxyReferer=https:%2F%2Fwww.google.com%2F)

#### Deep Knowledge Tracing(DKT)
Knowledge Tracing: 학습자의 퍼포먼스를 바탕으로 학습자의 전체 지식 수준을 평가하는 Task를 말한다
- 정오답 결과를 바탕으로 학습자의 지식 수준에 해당하는 전체 문제 세트에 대한 정답률 예측 결과를 내보내게 된다
    -  가장 중요한 가정은 바로 문제 풀이 순서에 따라서 학습자의 학습 효율이 달라질 수 있다는 점
- RNN 사용하는듯?

[참조](https://hcnoh.github.io/2019-06-14-deep-knowledge-tracing)

[참조2](https://medium.com/@mldevhong/%EB%85%BC%EB%AC%B8-%EB%B2%88%EC%97%AD-deep-knowledge-tracing-%EB%B2%88%EC%97%AD-9979302e0c3d)

[참조3](https://riiidtechblog.medium.com/%EA%B5%90%EC%9C%A1ai%EC%9D%98-%EA%B8%B0%EB%B3%B8%EC%9D%B4%EC%9E%90-%EC%8B%9C%EC%9E%91-deep-knowledge-tracing-dkt-8bc132eda9ec)


#### OCR 기반의 글자 검출
Optical Character Recognition(광학 문자 인식): 사람이 쓰거나 기계로 인쇄한 문자의 영상을 이미지 스캐너로 획득하여 기계가 읽을 수 있는 문자로 변환하는 것

[참조](https://ko.wikipedia.org/wiki/%EA%B4%91%ED%95%99_%EB%AC%B8%EC%9E%90_%EC%9D%B8%EC%8B%9D)


#### 모델 최적화(CPU, GPU향 최적화)

## 피어 세션
논문에서 related work는 먼저 스킵해도 됨.

피어세션 중 나온 추천링크
- https://curt-park.github.io/2017-03-26/yolo/
- http://hoondongkim.blogspot.com/2019/03/recommendation-trend.html
- https://www.notion.so/c3b3474d18ef4304b23ea360367a5137?v=5d763ad5773f44eb950f49de7d7671bd
- http://hoondongkim.blogspot.com/2019/03/recommendation-trend.html

