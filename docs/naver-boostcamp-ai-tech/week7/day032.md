# day 32

## Image classification 2

### Going deeper with convolutions
- neural network를 깊게 쌓으면, 더 많은 것을 나타낼 수 있고, 더 큰 receptive field를 가질 수 있다
- 하지만 깊게 쌓으면 문제가 생기는데
    - Gradient vanishing / exploding
    - 더 많은 연산이 필요 (better or more GPU required)
    - ~~오버피팅 문제~~라고? 예상했지만, Degradation problem으로 성능 저하
### GoogLeNet
> Inception module
- 하나의 layer에 다양한 크기의 conv를 width로 늘리고, channel 축으로 concanate하여 넘김
    - 네트워크 사이즈가 커지면 더 많은 리소스를 사용하게 되는데
    - 이를 방지하기위해 1 by 1 conv(bottleneck layers)를 사용하여 dimension을 줄임
        - 공간 크기는 변하지 않고 channel 수만 줄임
- 구조는 기본 cnn 부분이 있고 - 여러개의 inception modules가 있음 - classifier output(a single Fc layer)
    - Auxiliary classifiers
        - 중간 결과에서 classifier를 주어 loss 측정 -> 여기의 loss에 backpropagation
        - 중간 gradient descent발생하여 사라진 gradient를 학습을 위해 주입하는듯?
- Auxiliary classifier
    - 중간 중간 loss 계산 
    - 학습 도중에만 사용하고 실제 테스트시에는 사용안함

### Resnet
- 최초로 100개 이상의 layer를 쌓았고, 인간 level을 넘음
    - depth를 깊게 가져가면 좋다!
    - degradation problem
        - 초기에는 성능저하가 overfitting인줄 알았음. 하지만, 그렬 경우 training에서 deeper의 error가 낮게 나오고, 실 테스트에서 에러가 높게 나와야하지만, 둘 다 낮음
        - 즉, overfitting 문제가 아님
- [Residual block](https://www.youtube.com/watch?v=ZILIbUvp5lk&ab_channel=DeepLearningAI)
    - skip connection(short cut)해서 깊은 layer에 전달 되는 것
    - residual block을 사용하면 깊은 신경망을 훈련시킬 수 있음
    - plan network에 skip connection을 더한 것
    - 더 깊은 신경망을 큰 성능저하 없이 생성할 수 있게 해줌!
- [Why resnets work](https://www.youtube.com/watch?v=RYth6EbBUqM&ab_channel=DeepLearningAI)
    - layer를 쌓았는데 f(x)의 연산의 weight과 bias가 0이면 residual값만 남음
    - layer를 통과한 결과값이 0 일때 단순히, 항등함수를 학습
        - layer를 통과한 값이 0이 아니면, 그냥 그 값을 학습 -> **그러므로 + residual 하는 것은 doesn't hurt but helps**
        - 항등함수와 기존 함수의 차원은 같아야함
- 중간에 다 거치거나, 하나도 안 거치거나, 하나만 두개만 등 다양한 path를 거치는 경우의 수가 생김
    - O(2^n) implicit paths conencting input and output
- Residual block architecture
    - 3 by 3 conv layers
    - batch norm after every conv layer
    - 각 블록별로 채널 수는 두배로 늘어나지만, stride 2로 공간 수는 줄임

### Beyond ResNets
- DenseNet
    - Resnet: element-wisely, 두 가지 신호를 합침 ( + )
    - 바로 직전의 입력을 넘기는 것뿐만 아니라 훨씬 이전의 layer의 정보도 넘겨받음
    - 두 신호를 concante해서 보존
- SENet
    - Attention across channels
    - depth를 높이거나 connection을 새로하는 것이 아니라 현재 주어진 activation의 관계가 더 명확해질 수 있도록 체널관의 관계를 모델링하고 중요도를 파악! new weighting해서 중요한 특징을 attention할 수 있게
    - squeezeL global average pooling을 통해서 각 채널의 공간정보를 없애고 각 채널의 분포를 구함 (H,W의 공간 정보를 1로, 채널에 평균정보만 포함)
    - excitation: FC layer로 앞에 나온 벡터를 W를 거쳐 채널간의 연관성을 고려하여 channel을 new weithing 또는 gating하는 attention score 생성
        - 중요한것은 강하게 아닌것은 gating으로 막거나 약하게
- EfficientNet
    - 채널축을 늘리고, layer를 쌓고, image resolution을 큰 것을 input으로: 이 세개의 feature를 동시에 잘 scale 하는 것(사람이 아닌 기계로)
- Deformable convolution
    - 자동차가 아닌 생물체의 팔다리가 각기 다른 위치로 움직이는 것을 적용
    - grid가 서로 다른 offset을 갖고 다른 방향!
        - 결과물은 네모가아닌, 동물에 shape에 맞게 펴져서

### CNN Backbone
- GoogLeNet이 {AlexNet, VGG, ResNet}보다 성능이 좋지만, 사용하기 복잡함
- 그래서, backbone으로 VGGNet과 ResNet을 많이 사용

## Semantic segmentation
### What is semantic segmentation?
- image classifaction을 영상 단위가 아닌 pixele단위로 하는 것
    - 같은 class이면서 다른 물체구분은 안함 (-> instance segmentation)
- 컴퓨터를 이용해서 사진을 편집하는데 사용 등 다양한 분야에서 사용

### Fully Convolutional Networks
- semantic segmentation에서 처음으로 end to end architecture(end to end는 사람의 손을 안타고 머신으로만 돌아가는. 즉, intput -> output)
- 임의의 image 사이즈를 받고, 그 image의 크기로 output결과를 냄
> Fully connected layer vs. Fully convolutional layer
- Fully connected layer(image classification): output a fixed dimensional vector and discard spatial coordinates
    - output: 공간정보 고려 -x
- Fully convolutional layer(Segmantic segmentation): Output a classification map which has spatial coordinates
    - 입력도 activation map, 출력도 activation map
    - 채널축으로 flattening
    - 1 by 1 convolution으로 슬라이딩 윈도우
- 문제가 있음! 예측값으로 나온 score map의 해상도가 매우 낮음
    - (stride나 pooling layer 때문에 최종 activation이 저해상도)
    - large receptive field를 갖기 위해, 여러 pooling layer를 거쳤기 때문
    - 해결책: scope map을 upsampling하여 더 크게
- Upsampling: activation map을 원래 사이즈에 맞춰주기 위해(to the size of the input image)
    - Stride나 pooling을 제거하면 작은 activation map을 얻을 수 없는 대신 고행사도 activation map을 유지. 하지만, 문제는 같은 layer를 사용해도 receptive field가 작아서 전반적인 정보 파악 불가능
    - 그래서, 일단 activation map의 크기를 작게 만들어서 receptive field를 키워놓고, 후에 upsampling으로 해상도를 맞춰주는 것
- transposed convolution
    - checkerboard artifact문제 발생 가능
    - convolutional kernel size와 stride parameter를 잘 조정하여 중첩이 생기지 않도록 해야함
    - 학습 가능한 upsampling을 하나의 layer로 한방에 처리
- 해당문제를 해결하기 위해 spatial upsampling과 feature convolution 단계를 나눔
- 낮은 layer: 좀 더 디테일하고 작은 범위
- 깊은 layer: 해상도는 낮아지지만 큰 recptive field로 영상의 전반적이고 의미론적인 정보를 포함
- semantic segmentatino에서는 정보 둘 다 필요함
    - 물체의 안과 밖을 다 표현해야하기 때문에
- 여러 layer의 pool 및 conv의 activation map을 concanate해서 사용!
- FCN은 사람의 별도의 알고리즘이 들어가지 않고 모두 NN으로 구현되어 있어, GPU로 병렬처리가 가능함으로 빠름
- Hypercolumn: 같은 년도에 같은 학교에서 나온 비슷한 논문(FCN과 비슷)
    - 여기도 여러 lyaer의 activation map의 해상도를 맞춰서 같이 쓰는 것을 강조
    - bounding box를 추출하는 third party를 사용했기 때문에, end to end가 아님

### U-Net
- FCN모델이고, skip connection을 도입함. 그래서 좀 더 정교한 결과를 얻음!
    - contracting path
        - 3 by 3 convs를 반복적으로 사용
        - 밑으로 내려갈수록 receptive field를 크게 확보하기 위해 해상도를 낮추고 채널 수를 늘림
        - 작은 activation map을 구함
    - Expanding path
        - 점진적으로 upsampling(한번에 x)
        - 대칭되는 layer를 skip connection을 통해서 가져옴
            - compacting path에서 오는 대칭으로 오는 layer와 맞춰서 낮은 층에서 오는 layer와 합쳐서 사용할 수 있게 만듦
        - 채널 사이즈가 줄고 해상도가 점점 늘어남
    - 낮은 layer에서는 localized 정보를 준다
        - 경계선이나 공간적으로 중요한 정보를 뒷쪽에 전달하는 역할
- feature map의 사이즈가 홀수일 경우?
    - 7 by 7으로 시작해서 7 by 7으로 돌아오지 않음
    - 그러므로, 중간에 어떤 layer도 홀수 해상도의 activation map이 나오지 않도록 주의
### DeepLab
- CRF(Conditional Random Fields)후처리로 사용되는 툴
    - 그래프 모델이 들어감
    - pixel과 pixel의 관계를 이어줌
- Dilated convolution
    - convolution 사이에 dialatino factor만큼 일정 공간을 뛰어줌
    - parameter 증가 없이 더 넓은 공간 고려 가능(receptive field 증가)
- depthwise separable convolution
    - 두 개로 나누어 parameter 계산량을 줄임 (지수승6 에서 지수승5 + 지수승4)
- Semantic segmentation보다 요즘은 Instancfe segmentation에 더 많은 논문이 나오는 추세

## 피어세션
- 전반적으로 수업내용에 대한 토론을 진행
- CIFAR-18 화이팅