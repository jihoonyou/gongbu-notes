# day 033

## Object detection
### What is object detection?
- semantic segmentation보다 더 구체적
- 객체가 달라도 구분이 되는 것!
- Instance segmentation ⊂ Panoptic sementation
- Object Detection = Classification + Box locallization
    - 분류와 bouding box 동시 추정
    - (Pclass, Xmin, Ymin, Xmax, Ymax)
    - Autonmous driving이 있고, Opticall Chracter Recognition

### Traditional methods - hand-crafted techniques
> Gradient-based detection
- 과거 neural network를 접목하기전에 detection으로 영상의 경계를 평균을 냈다
    - 사람의 직관에 의해 알고리즘 설계
- feature를 정교하게 사람이 design하고, ML 알고리즘은 linear model을 사용
    - 영상의 gradient를 기반으로 한 detector가 많이 사용됨
> Selective search
- 사람외에 다양한 물체 후보군에 대해 영역 측정(bounding box)
1. Over-segmentation: 영상을 비슷한 색끼리 잘게 분할
2. Iteratively merging similar regions: 비슷한 영역끼리 합침 (비슷 = 색,분포, gradient 특징)
3. Extracting cadidate boxes from all remaining sementations: 반복해서 합친 결과에서 후보군 박스를 추출

### R-CNN
> Directly leverage eimage classification networks for object detection
- 과거 AlexNet처럼 해당 분야(object detection)에서 상대적으로 높은 정확도를 갖고 나옴
1. Input image
2. Extrack region proposals(~2k)
    - Selective search 같은 알고리즘으로 Region을 구함
3. CNN에 넣기 위해 warped region (ex. 244 by 244) - cnn의 input에 적잘한 사이즈로 warping
4. Compute CNN feature
5. Classify regions
    - CNN에서 나온 feature를 기반으로 linear 기반의 SVM을 학습하여 분류
- 단점:
    - 각 region proposal 하나하나마다 모델에 넣어서 processing에 넣어서 속도가 굉장히 느림
    - region proposal을 hand-designed된 알고리즘을 사용해서 학습을 통한 성능 향상의 단점이 있음

### Fast R-CNN
> Recycle a pre-computed feature for multiple object detection
- 영상 전체에 대한 feature를 추출하고 재활용하여 여러 detection을 도출
- warping이 사라짐
1. Conv. feature map from the original image
    - fully convolutional한 network는 입력사이즈에 상관없이 feature-map 추출 가능(이제 warping x)
2. RoI feature extraction from the feature map through RoI pooling
    - 한번 뽑아놓은 feature를 여러번 재활용하기 위한 layer
    - (Region of interest)region proposal이 제시한 후보위치들을 의미
    - RoI에 해당하는 feature들만 추출, fixed size를 가질 수 있도록 resizing
3. Class and box prediciton for each RoI
    - Bouding box regression & classification
- train speed가 빨라졌지만 사람의 알고리즘(selective search)이 들어가 성능에 한계까 있음 

### Faster R-CNN
> end to end boject detection by neural region proposal
- region proposal을 neural network기반으로 대체
- IoU(Intersection over Union)
    - Area of Overlap / Area of Union (합집한분의 교집합)
    - 두 영역에 오버랩을 정해주는 기준
- Anchor boxes: 각 위치에서 발생할 것 같은 박스들을 미리 정의해둔 후보군
    - a set of pre-defined bounding boxes
    - 서로 다른 scale과 비율을 정의하여 사용
    - groud truth가 높은 친구를 positive, 나머지 후보군은 negative에 대한 loss를 주어 학습
- 가장 큰 변화는 오래걸리는 selective search를 region proposal network로 대체한 것!
1. 영상하나에서 공유되는 feature map을 뽑는다
2. RPN을 통해 region proposal제안 (bounding box)
3. Region proposal로 RoI pooling
    - RoI pooling: 어떤 regional proposal이 들어오더라도 max pooling을 이용하여 결과의 Output size가 같게
4. classification & bounding box 수행
- feature map에서 fully convolutional network로 sliding window하여 매 위치마다 K개의 anchor box를 고려
    - 각 위치에서 254-d feature vector 추출
- cls layer: 2k scores (object vs. non-object) => crossentropy loss 
    - object인지 아닌지 각각의 k개의 anchor box에 구분하는 classification score가 나옴
- reg layer: regression loss
    - (x,y,w,h)
    - 박스를 다시 조정하는 이유는 anchor box가 엄청 촘촘하면 조정이 필요 없지만 성능이 구림
    - 적당히 만들고 reg layer에서 더 정교하게!
- Non-Maximum Suppresion (NMS)
    - 실질적으로 threshhold를 넘는 많은 bounding box가 나옴
    - RPN이 허수를 필터링 해줌

### Comparison with two-stage detectors
- Two-stage detector
    - sampling된 위치에 대해서 classification
- One-stage detector
    - no explicit RoI pooling
    - Region proposal을 기반으로 한 RoI pooling을 사용하지 않고 바로 box regression과 classification
### YOLO
- input을 s by s grid로 나누고 각 grid별로 bounding boxes, confidence score, class probabilty map 예측
- output: NMS를 적용하여 출력
- Ground truth와 매치된 anchor box들을 postive로 간주하고 학습 label을 postive로 걸어줌
- 구조는 일반 CNN과 동일
- s by s는 convolution layer에서의 마지막 해상도로 결정됨
- faster RCNN보다 성능이 떨어지지만 빠름
### Single Shot MultiBox Detector (SSD)
> The use of multi-scale outputs attached to multiple feature maps enable effectively modeling a diverse space of possible box shapes
- YOLO는 맨마지막 layer에서 한번만 예측하기 떄문에 성능이 떨어짐
- 이를 보완하기 위해 SSD가 나옴
- 각 featuremap의 크기마다 다른 bounding box를 예측할 수 있도록!
    - 각 scale마다 object detection 결과를 출력하도록 하여 다양한 스케일의 object들에 대해 잘 대응하게 설계

### Focal loss
- class imblance problem (#neg. anchor boxes > #pos. anchor boxes)
- RoI pooling이 없다보니 모든 영역에 대해서 계싼을 시행
    - 대부분의 영상은 positive sample보다 negative sample이 더 많음
- Focal loss: cross entropy의 확장
    - 어렵고 잘못판별된 부분에는 더강한 weight을 주고, 더 쉬운 부분에는 낮은 weight

### RetinaNet
> Feature Pyramid Network + class/box prediction branches
- low level의 특징과 high level 특징을 둘 다 활용 (각 scale별로 특징을 찾기 위함)
    - classification과 box regression을 각각 dense하게!
### Detection with transformer
- transformer를 object detection에 적용
- DETR

### Further reading
- detecing object as points
    - bounding box regresison말고, 다른 형태로 데이터를 탐지하는 연구
    - box위치 대신 물체의 중심점을 찾고 물체의 경계를 찾는 등..

