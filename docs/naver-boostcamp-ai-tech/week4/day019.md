# day 19

## Neural Machine Translation of Rare Words with Subword Units
### 1. Introduction
- Our main goal is to model open-vocabulary translation in the NMT network itself, without requiring a back-off model for rare words
- In addition to making the translation process simpler, we also find that the subword models achieve better accuracy for the translation of rare words than large-vocabulary models and back-off dictionaries, and are able to productively generate new words that were not seen at training time.
- Our analysis shows that the neural networks are able to learn compounding and transliteration from subword representations
- two main contribution
    - We show that open-vocabulary neural machine translation is possible by encoding (rare) words via subword units. We find our architecture simpler and more effective than using large vocabularies and back-off dictionaries
    - We adapt byte pair encoding (BPE) (Gage, 1994), a compression algorithm, to the task of word segmentation. BPE allows for the representation of an open vocabulary through a fixed-size vocabulary of variable-length character sequences, making it a very suitable word segmentation strategy for neural nework model
### 2 Neural Machine Translation
- The neural machine translation system is implemented as an encoder-decoder network with recurrent neural networks.
    - encoder is a bidirectional neural network with gated recurrent units
    - The decoder is a recurrent neural network that predicts a target sequence
### Subword Translation
- The main motivation behind this paper is that the translation of some words is transparent in that they are translatable by a competent translator even if they are novel to him or her, based on a translation of known subword units such as morphemes or phonemes
- Our hypothesis is that a segmentation of rare words into appropriate subword units is sufficient to allow for the neural translation network to learn transparent translations, and to generalize this knowledge to translate and produce unseen words

## 조교 세션
- manage session들어가보면 탭을 닫아도 session이 남아있는것을 보여줌
    - `!pip` colab내에서 커멘드
- fairseq 파일을 pip으로 인스톨하고
- clone도 함
- fairseq 
- 실제 사용에 커멘드 라인 툴을 사용해서 학습
- task
    - sequence task (translation, ln task)
- Model
    - 어떤 모델을 제공하는지 나와있음
    - 하이퍼파라미터 조정 가능
- criterion
- optimizer
- 조교님은 자주 안쓰심
    - cmd로 써야하기 떄문에.. 모델 변형 및 전처리를 수정하기가 어려워서
    - scratch부터 직접 train해서 진행하는 reference는 좀 부족한듯
    - 실제 docs에 없는 argument를 git example내에서 확인할 수 있음
- OpenNMT - 자주 사용되는 라이브러리
- Huggingface - 안에 transformer library를 많이 사용하게 될듯
    - 여기 안에 transformer base로 구현된 라이브러리가 많음
    - 유명한 모델들이 많음
    - 내일 활용하게 될듯
    - git 에서 transformer/example/seq2seq/ 를 들어가서 (NER은 token-classification)
        - run-ner 코드 베이스를 기준으로 수정할예정!
    - config_classes
        - pretrained된 class 데려오는듯
    - 전처리한것을 local에 저장 (caching)
        - load_and_cache 수정하면 활용할 수 잇는듯
    - Pycharm 추천
    - Electra model
    - 우리는 3.3.1버전을 사용할 예정
        - release에서 해당 버전 선택!
        - transfoemrs/src/transfomers
    - pdb (debugger) 사용해볼 것
        - 근데 생산성을 위해 pycharm 추천
### Hyperparameter Tuning in Pytorch
> GPU가 한정되있으므로, 노가다를 좀 더 빠르게 높은 성능에 도달 할 수 있게
- random seed
    - 좀 유명한 seed가 있음 (seed마다 성능이 다르게 나옴)
    - 같은 모델에 시드만 다른데 퍼포먼스가 이상하게 나온 것도 있음
    - random seed를 많이 할수록, 더 많은 거를 돌려볼수록
- How to control randomness
    - A라는 서버에서 돌릴거를 B라는 서버에서 돌려보고 싶다
        - random.seed를 컨트롤하여 재현가능
    - 하지만 이걸해도 재현이 안됨 (OS가 다르거나, Cuda version이 다르거나, )
        - random generate table이 CPU마다 다를 수 있음
    - H/W가 똑같다는 가정하에 재현만 가능한듯?

### Hyperparameter Tuning
- grid search 
    - 연속적인 스케일로 나타낼 수 있다면..
- random search
    - 랜덤하게 값을 선정해서 서치를 하게 됨
- rnadom search가 grid search보다 훨씬 좋음
- bayesian search
- 중요한 parameter가 뭐냐?
    - learning rate
    - batch size
        - 이거는 우리가 컨트롤 할 수 있는 여지가 별로 없음 (가진 리소스에서)
        - 키울 수 있는 만큼 키우기
    - Answer ng이 여러가지 중요하다가 말했지만 우린 그런 시간이 없음
- 그럼?
    - 사실상 learning rate이 제일 중요함
    1. learning rate shceduler를 끊다! 그리고 모델 학습 시킴 (random search로)
        - 끝까지 다 학습 안해도 됨
        - 일반적으로 초반에 학습효과가 좋은 것들이 효과가 좋음
        - early stage에서 learning rate를 여러개 잡아서 튜닝을 해보셉
    2. 유난히 로스가 낮은 로스 레인지를 찾을 수 있음
        - 그럼 trun on learning rate scheduler and train a model을 킴
            - 1~ 100까지 했으면, 1~10으로 줄여서! 확인해봄
            - 여기서도 early stage에서 잘하는 애들이 잘 하는 애들이 잘할 가능성이 높음
            - random search
            - batch size는 크기가 보장하는 한 키워보셉
    3. 러닝커브를 자세히 봐야함
        - 절대적으로 언제부터 확인해야되는지는 없음
        - 내가 봤을 때.. 이런 모양인 것 같다. 주식 그래프 예측 느낌으로 해야함.
        - 아마 쭉 안덜어지면, initialization 방법이 잘못 될 수 있다 라고 가정 가능
        - 또는, 로스가 더 떨어져야 할 것 같은데.. 안 떨어지네 하면.? -> learning rate decay를 해보셉
            - bubbly decent 논문 확인
        - 왜 training loss curve만 보나? - validate 할 리소스가 많이 없기 때문에
        - step 3는 training loss만 보고 해보는 듯
    4. training rate을 충분히 봤다면, validate curve를 보고 판단해봅
        - 같이 찍어봅, 근데 오래거리린? 듬성듬성 해봐랍
        - 점점 validation accuracy가 떨어진다면.. overfitting일 수 있으므로, 또는 갭이 크면 regularization
        - 혹시나 gap이 너무 적으면, underfitting 의심가능
- 결론
    - 최대한 배치사이즈로 
    - evaluation이 낮은 지점을 잘 찾아라 (generalization이 잘되는 모자)
    - cross validation은 비추 (리소스가 없는데 그건 비추)
        - 그 리소스를 할애할발에 다른 parameter를 가진 모델을 돌리는게 이득
    - test + validation set을 합쳐서.
        - 합친 다음에 ..? 리소스가 너무 작으면 그냥 합쳐서 Train
        - train set + validation set => test score를 높이는 잔기술
    - 무조건 앙상블해라!
        - 같은 모델을 두고, 랜덤시드만 다르게해서 학습을 시키는 것
    - 다른 모델에서 쓰는 (영어든 뭐든) 에서 쓴 거를 start point를 맞춰서 시작하면 좋음
- step 4에서 learning rate를 고정하고 그 다음에 다른 거 건드리나? 근데 효과가 없을?
- 조정할 때 가장 우선시되는 파라미터로는 learning rate외에 어떤 것이 있나요?
    - learning rate랑 warmup step도 많이 그 다음은 batch-size
    - 지금 설명은 model을 무시하고 말했기 때문에, + task마다 바뀔 수 있음
- 베이스라인 모델은.. 뭐로 할까.?
    - transformer 기반 
    - Bert이후 많은게 나옴
    - 좀 더 오래되고 더 많은 사람들이 썻을수록, 점수가 공개되어 있음!
    - 개인적으로는 너무 최신말고: 여러데이터셋에서 벤치마킹 및 검증이 된것을 써라
        - 그 베이스라인 모델로 수정이 용이한 것
        - 엑셀넷? 그건 좀 어려울듯
        - 엑셀넷만큼 비슷한 성능이 나오고 좀 더 쉬운 코드로 나온 코드를 베이스라인으로 
        - 라이브러리에서 제공하는 베이스라인 코드를 선택해서 해보는거 추천하시는듯
        1. 너무 최신 x
        2. 저자 이외 많은 사람들이 다양한 task에 적용된걸 쓴다
        3. 유명한 라이브러리에서 제공하고 있는 코드를 제공하고 있는걸 쓴다
        4. 너무 어렵게 코딩 된 코드를 쓰지 않는다