# day 8 Pandas I / 딥러닝 학습방법 이해하기

## pandas I
> 구조화된 데이터의 처리를 지원하는 Python 라이브러리
> Python계의 엑셀!

### pandas
- 구조화된 데이터의 처리를 지원하는 Python 라이브러리
- panel data -> pandas 
    - 금융쪽 개발자가 만듦
    - R에 있는 data 구조체와 유사
- 고성능 array 계산라이브러리인 numpy와 통합하여, 강력한 “스프레드시트” 처리기능을 제공
- 인덱싱, 연산용 함수, 전처리 함수 등을 제공함
- 데이터 처리 및 통계분석을 위해 사용

- 앞으로 다룰 데이터는 matrix 행렬 데이터, 엑셀 sheet 데이터
- DL, Image, Sound, Text
- Pandas는 Tabular(테이블형) data를 다루는데 최적화가 되있는 도구

![table_naming](../../images/table_naming.png)

### 데이터 로딩
```
import pandas as pd #라이브러리 호출

# data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data' #Data URL
data_url = './housing.data' #Data URL
df_data = pd.read_csv(data_url, sep='\s+', header = None) #csv 타입 데이터 로드, separate는 빈공간으로 지정하고, Column은 없음

df_data.head() #처음 다섯줄 출력

df_data.columns = [
    'CRIM','ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO' ,'B', 'LSTAT', 'MEDV'] 
# Column Header 이름 지정

df_data.head()

df_data.values
```

### pandas의 구성
![pandas_structure](../../images/pandas_structure.png)

### Series
> column vector를 표현하는 object
![series](../../images/series.png)
![series_example](../../images/series_example.png)
- data를 접근하는 indexing을 문자로 지정할 수 있음

![series_explanation](../../images/series_explanation.png)
![series_example3](../../images/series_example3.png)
- `example_obj.astype(float)`
    - type 변경
- `example_obj.values`: 값 리스트만
- `example_obj.index`: index 리스트만
- `example_obj.name`: 잘 안씀 (series name 지정)
- `example_obj.index.name`: 잘 안씀 (index name 지정)

- index를 값을 기준으로 series 생성
    - data를 넘어가는 index NaN로 표시

### dataframe memory
![dataframe_memory](../../images/dataframe_memory.png)
- series를 모아서 data frame(table)을 만듦 = 기본 2차원
    - 기본적으로 CSV, excel형 데이터를 부름

### dataframe 생성
![dataframe_creation](../../images/dataframe_creation.png)
![dataframe_creation2](../../images/dataframe_creation2.png)
- `df.first_name` or `df["first_name"]` - column 선택 - series 추출

### dataframe indexing
- `df.loc[1]` loc - index location
    - `df.loc[:3]`
        - 3이라는 이름의 index까지
        - index의 이름을 쓰는것!
    - `df.loc[:, ["last_name", "first_name"]]`
- `df['age'].iloc[1:]` iloc - index position
- loc은 index 이름, iloc은 index number

### dataframe handling
```
df.age > 40
df.debt = df.age > 40
df
values = Series(data=["M", "F", "F"], index=[0, 1, 3])
values
df["sex"] = values
df

```
`df.T` - transpose
`df.values` - 값 출력
`df.to_csv()` - csv 변환
`df.index`
`del df['debt']` - column 삭제
`df.drop('debt', axis=1)` - axis1 - column 기준 drop(df 원본 변환 x)
 
 `pop = {"Nevada": {2001: 2.4, 2002: 2.9}, "Ohio": {2000: 1.5, 2001: 1.7, 2002: 3.6}}`
 - 앞에 dict는 column, 안은 index값

## pandas II

### Selection with column names
- df['account'].head(3) : 한개의 column 선택시
- df[['account, 'street', 'state]].head(3) : 1개 이상의 column 선택
엑셀 파일 읽어오는 모듈
- `!conda install --y xlrd` 
df['account'] vs. - df[['account']]
- series 형태         dataframe 형태 
![selection_example](../../images/selection_example.png)
- index data가 'a', 'b', 'c'면 위의 코드로 동작 x
- fandy index, boolean index 가능!!

### index 변경
```
df.index = df['account']
del df['account']
df.head()
```

### basic, loc, iloc selection
![selection_example2](../../images/selection_example2.png)

### reindex
```
df.index = list(range(0,15))
# df.reset_index(drop=True)

# df.reset_index(inplace= True, drop=True)
```
- `inplace = True`하면 값이 변경됨
    - 보통 자기 자신이 변하게 잘 안함

### data drop
`df.drop(1)` 
- index number로 drop
    - drop 도 실제 데이터에 변환을 하는 건 아님! (inplace = True해야함)
`df.drop('city', axis=1)` # df.drop(['city', 'state'], axis=1)
- axis 지정으로 축을 기준으로 dop -> column 중에 'city' 
`df.drop('city', axis=1, inplace=True)`

### dataframe operations
![series_operation](../../images/series_operation.png)
- 모든 연산은 index(column 값)를 기준으로 연산
- series에서는 indexr값에 중복을 허용
![dataframe_operation](../../images/dataframe_operation.png)

### series + dataframe
![series_df_operation](../../images/series_df_operation.png)

### lambda, map, apply

### map for series
- pandas의 series type의 데이터에도 map 함수 사용가능
- function 대신 dict, sequence형자료등으로 대체 가능
![map_for_series1](../../images/map_for_series1.png)
![map_for_series2](../../images/map_for_series2.png)
![map_for_series3](../../images/map_for_series3.png)

### replace function
- map 함수의 기능중 데이터 변환 기능만 담당
- 데이터 변환시 많이 사용하는 함수
![replace_function](../../images/replace_function.png)

- `!wget URL`
    - 다운로드 받는 코드

### apply for dataframe
- map과 달리, series 전체(column)에 해당 함수를 적용
- 입력 값이 series 데이터로 입력 받아 handling 가능
![apply_for_df](../../images/apply_for_df.png)

- `df_info.sum()` = `df_info.apply(sum)`
- 내장 연산 함수를 사용할 때도 똑같은 효과를 얻을 수 있음
- mean, std, sum 등 사용 가능 
```
def f(x):
    return Series([x.min(), x.max()], index=['min', 'max'])
df_info.apply(f)
```
- scalar 값 이외에 series값의 반환도 가능함

### applymap for dataframe
- sereis 단위가 아닌 element 단위로 함수를 적용함
    - 모든 단위
- series 단위에 apply를 적용시킬 때와 같은 효과
    - column 단위
![apply_for_dataframe](../../images/apply_for_dataframe.png)

**apply는 column 단위로 적용된다는 것을 기억해두면 좋을듯**

### pandas built-in functions

### describe
- Numeric type 데이터의 요약 정보를 보여줌
![apply_for_dataframe](../../images/apply_for_dataframe.png)

### unique
- series data의 유일한 값을 list로 반환함

### sum
- 기본적인 column 또는 row 값의 연산을 지원
- sub, mean, min, max, count, median, mad ,var 등
- `df.sum(axis=0)` column 별, `df.sum(axis=1)` row 별
    - 축을 기준으로 해서!

### isnull
- column 또는 row의 값의 NaN (null) 값의 index를 반환함
- `df.isnull()`
- `df.isnull().sum`
    - 얼마나 비어져있는지 확인 가능

### sort_values
- column 값을 기준으로 데이터를 sorting
`df.sort_values(["age", "earn"], ascending=True).head(10)`
    - index값이 섞이는 거 주의!

### Correlation & Covariance
- 상관계수와 공분산을 구하는 함수
- corr, cov, corrwith
- `df.age.corr(df.earn)`
- `df.age.cov(df.earn)`
- `df.corrwith(df.earn)`
- `df.corr()`
    - 모든 column들 간의 상관관계
- 필요할 때 찾아보자!

`df.isnull().sum() / len(df)`
- null 비율


`pd.options.display.max_row = 2000`
- 를 사용하여 한번에 출력되는 수를 조정할 수 있다!

`df["sex_code"] = df["sex"].replace({"male": 1, "female": 0})`
- 숫자로 바꿔서 correlation을 확인 가능!

`df.corrwith(df.earn)`
- 하나의 column에 관해 각 correlation을 보고 싶을 때

`df.sex.value_counts(sort=True) / len(df)`

## 딥러닝 학습방법 이해하기
- 해당 섹션은 수업자료 PDF에 필기를 진행하였습니다.

### 리뷰
데이터를 선형모델로 해석하는 방법(경사하강법)
- 주어진 데이터에 정답에 해당하는 y와 선형모델의 결과인 y-hat의 차이의 l2 norm의 기대값을 최소화하는 vector를 찾는 학습을 했음
    - 단순한 문제는 괜찮지만, 분류 문제 및 좀 더 복잡한 것에 적합하지 않음

### 신경망으로 수식을 해석해보자

비선형 모델인 신경망(neural network)
- 실제 수식적으로 분해해보면 선형모델이 안에 숨겨져 있고, 그 선형 모델과 비선형 함수의 결합으로 이루어져 있음


![linear_model](../../images/linear_model.png)
- 전체 데이터 행렬 X
- X의 데이터 행렬 포인트를 출력으로 뱉어주는 가중치 행렬 W
    - 다른 데이터 공간으로 보내주는 W
- WX 두개의 곱을 통해서 선형모델을 표현
- B - y 절편
    - 각 행에 대해서 모두 같은 값을 더해준다.
- XW + B = O - 출력
- 출력 베터의 차원은 d에서 p로 바뀌게 됩니다.

![nn_pic](../../images/nn_pic.png)
- 화살표가 W 가중치

분류 문제
- 주어진 문제가 어떤 클래스에 해당하는지 분류하는 문제!


### 소프트맥스 연산
- 분류 문제를 풀 때 필요한 연산자
- 모델의 출력을 확률로 해석할 수 있게 변환해주는 연산
    - 분류 문제를 풀 때, 선형모델과 소프트맥스 함수를 결합하여 예측합니다
    - 확률 벡터로 변환
        - 주어진 데이터가 특정 클래스에 속할 확률이 얼마인지 계산
- exponential 함수 

- 만약 너무 큰 vector가 들어오면 overflow가 들어올 수 있어서..  - np.max를 해줌

소프트맥스는 학습을 할 때는 필요하지만..

추론을 할 때는
- 출력값에서 가장 최대값을 가진 주소만 1로 출력하는 one-hot vector를 사용
    - 굳이 softmax 사용할 필요 없음
    - one_hot(softmax(o)) - X
    - one_hot(o) - O

회귀 문제가 아닌 분류문제에서 softmax를 이용해서 선형모델로 나온 출력값을 분류문제를 해결할 수 있게함
- softmax가 아닌 다른 activation function를 활용할 수 있음


### 활성함수가 뭐에요?
- 실수값을 입력으로 받아서 다시 실수값으로 뱉는
- 활성함수를 쓰지 않으면 딥러닝은 선형모형과 차이가 없습니다

activation function
- 활성함수는 비선형함수로서 (선형모델로 나오는 각각의 원소에 적용)
- softmax와 차이: softmax는 출력물의 모든값에 다 고려해서
- af는 다른 것을 고려하지 않고 오직 해당 주소에 있는 값만 고려/적용하여 잠재벡터를 만듦
    - vector를 받지 않고 실수값만 받음
- 과거 sigmoid, tanh, 
- 최근 Relu

X를 input으로 해서 선형모델을 통해 Z라는 출력을 뱉으면, Z라는 출력물에 활성함수를 씌우면 새로운 잠재벡터인 H를 만들 수 있습니다. 이 H를 다시 출력으로 연결시키는 선형모델을 고려 할 수 있음
- 2-layers: 선형 모델이 두 개 세계가 되기 때문에(가중치 행렬을 두개로 사용하기 때문)
- 이렇게 선형모델과 활성함수를 반복적으로 사용하는 것이 딥러닝의 기본
- MLP(multi-layer perceptron반복적인 사용): 다층 신경망
- X를 입력으로 받아서 W1이라는 가중치 행렬을 통해 Z로 보내고, 그 Z를 활성화함수를 씌워서 H라는 잠재벡터로 보내게 되는것
    - 시그마를 씌울때(활성화함수) - 각 벡터에 개별적으로 적용(실수값으로 입력을 받음)
    - H는 Z의 모양과 똑같고 Z에 fb를 적용한 것

![mlp_eq](../../images/mlp_eq.png)
- MLP 패러미터는 L개의 가중치 행렬 WL,...W1과 y-절편 bL,...,b1 

forwardpropagation
- 학습이 아닌 주어진 입력이 왔을 때 출력물을 내뱉는 연산
- x라는 입력을 받아서, 최종 출력까지 보낼 떄, 선형 모델과 활성함수를 반복적으로 적용하는 연산 


### 왜 층을 여러개를 쌓나요?
- 이론적으로 2층 신경망으로도 임의의 연속함수를 근사할 수 있습니다.
- 그러나 층이 깊을수록 목적함수를 근사하는데 필요한 뉴런의 숫자가 훨씬 빨리 줄어들어 좀 더 효율적으로 학습이 가능합니다.
    - 적은 parameter로 더 복잡한 함수를 표현 가능
- 층이 얇으면 뉼너의 숫자가 기하급수적으로 늘어남
- 하지만, 층이 깊다면 좀 더 복잡한 함수를 근사할 수 있지만, 최적화가 쉬운 것은 아님.
    - 층이 깊어질수록 최적화에 더 노력해야함
- 좀 더 적은 뉴런과 노드를 가지고 복잡한 패턴을 표현할 수 있기 때문

### 딥러닝 학습원리: 역전파 알고리즘
backpropagation
- 경사하강법을 적용을 해서 각각의 가중치 행렬들을 학습을 시킬 때 각각의 가중치에 대한 gradient vector를 계산해야 경사하강법을 적용할 수 있다 
- 각 층에 존재하는 패러미터들에 대한 미분들 계산해서, 그 미분들을 갖고 패러미터를 업데이트 해야함
    - 행렬들의 y-절편 포함 모든 원소의 갯수만큼경사하강법이 적용됨
    - 선형모델 더많은 parameter가 적용된다는것
- 선형모델으 한층에서 계산하기 때문에 한번에 계산이 되지만, deep learning은 순차적으로 각 층에서 계산하기 때문에.. 역순으로 순차적으로
- 역전파 알고리즘의 목적: 각각의 가중치 행렬 Wl에 대해서 손실함수에 대한 미분을 계산할 때 사용

![back_propagation](../../images/back_propagation.png)
- 각 층에서 계산된 gradient를 밑에층으로 전달
- 저층에서는 위층에 결과값이 필요하기 때문에
    - 위층에서 아래층으로 역순으로 연쇄법칙을 통해 그레디언트 벡터를 전달
- 역전파 알고리즘은 합성함수 미분법인 연쇄벅침 기반 자동미분을 사용합니다
    - 자동미분은 여기서 설명 x
- 각 뉴런에 해당하는 값을 tensor라고 표현하는데, 이 각각의 tensor값은 컴퓨터에 메모리로 저장해야 동작하기 때문에.. 각 뉴런에 해당하는 tensor값을 컴퓨터에 저장해야함 => 메모리를 많이 사용

![back_propagation2](../../images/back_propagation2.png)
- w1에 대한 손실함수에 대한 미분 계산

정리: 딥러닝은 선형모델과 활성함수들의 여러층에 대한 합성함수, 합성 함수다 보니깐, gradient를 계산하기 위해 chain rule이 필요
    - chain rule을 적용한 학습방법 알고리즘인 back-propagation을 사용한다.

## 피어세션 
논문 마다 contribution 이 있음
- 이 논문을 써서 어떻게 기여할지 - **contribution**
    1. 개념 - 연구분야에 새로운 갠며을 찾아서 이렇게 기여 하겠다
    2. 실험 - 있는 것으로 결과 분석 
    3. 방법 - 문제가 있는데, 나는 이렇게 풀었다 하는 방법론
    - 표가 많은 것은.. 실험을 해봤는데..?
        - 비 연관적인 수식도 있을 수 있음
    - 방법론 쪽으로 contribution! 
- Speical thanks to 찬형

NLP 꿀자료
![NLP](https://wikidocs.net/book/2155)

내가 ..5시 팀 소개 발표..ㅠ

[눈문 잘 읽는 법](http://gradschoolstory.net/terry/readingpapers/?fbclid=IwAR33nLZiL1elnanViVpYItjpE3AnpVYjWJy8P8px2qoruqDSS5zDp76l_kU)

[논문 잘 쓰는 법](http://gradschoolstory.net/tag/%EB%85%BC%EB%AC%B8-%EC%98%81%EC%96%B4/)